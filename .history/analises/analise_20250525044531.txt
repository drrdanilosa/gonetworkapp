Perfeito. Vou reunir todas as informações analisadas no seu repositório, nos arquivos enviados e no fluxo descrito para compor um relatório técnico completo. Esse documento irá detalhar a arquitetura da aplicação, o fluxo funcional por etapa, as integrações entre as abas, o funcionamento das APIs e o controle de vídeos locais com watcher.

Ele será entregue diretamente aqui para você revisar, testar e, se desejar, colar direto no VS Code como documentação do sistema.

Vou começar agora e volto com o conteúdo completo assim que estiver pronto.


# Relatório Técnico do Sistema **MelhorApp** – Gerenciamento de Entregas Audiovisuais

## 1. Estrutura Geral do Sistema

### Organização de Diretórios

O projeto adota uma organização modular e escalável dos arquivos, distribuídos em diretórios de acordo com suas responsabilidades. Os principais diretórios incluem: **`app/`** (contendo as páginas e rotas API do Next.js App Router), **`components/`** (componentes React reutilizáveis, subdivididos em seções como UI genérica, componentes de vídeo, widgets funcionais, etc.), **`contexts/`** (contextos React globais), **`features/`** (módulos de funcionalidades agrupados por domínio, por exemplo autenticação, briefing do evento, etc.), **`hooks/`** (hooks customizados), **`lib/`** (funções utilitárias e bibliotecas), **`services/`** (serviços para chamadas à API/back-end), **`store/`** (gerenciamento de estado global com Zustand) e **`types/`** (definições de tipos TypeScript). Essa estrutura em “feature folders” melhora a escalabilidade e mantém uma separação clara de responsabilidades, facilitando a manutenção do código.

### Arquitetura em Camadas

A arquitetura do MelhorApp segue uma abordagem em camadas, garantindo baixo acoplamento entre componentes de interface, lógica de negócio e persistência. Na camada de **interface (UI)** estão os componentes React – muitos deles desenvolvidos com a biblioteca de design *shadcn/UI* e estilizados via Tailwind CSS – responsáveis por renderizar formulários, listas, players de vídeo e outros elementos visuais. Esses componentes são frequentemente organizados dentro das pastas de **features** (por exemplo, componentes específicos do Briefing dentro de `features/briefing/components`) ou na pasta geral de componentes para itens reutilizáveis. Na camada de **serviços**, o projeto define funções em arquivos dentro de `services/` para abstrair chamadas de API e integração com back-end. Por exemplo, há um `auth-service.ts` para login/registro e um `briefing-service.ts` para operações de briefing, atualmente usando *fetch* (ou simulações) para acessar rotas internas. Esses serviços facilitam a troca futura do back-end (hoje simulado) por um real, já que concentram a lógica de comunicação com a API.

O **gerenciamento de estado global** fica na camada de **store**, implementado com a biblioteca Zustand. Existem stores separados por domínio para organizar os dados: por exemplo, `useAuthStore` lida com estado de autenticação, `useProjectsStore` gerencia projetos/eventos, vídeos, comentários e anotações, `useCollaborationStore` trata de estados de colaboração em tempo real (Socket.io), e `useUIStore` para estados da interface. Cada store define estrutura de dados imutável e funções (actions) para modificar o estado (e.g. adicionar projeto, mudar status de um vídeo, adicionar comentário), muitas vezes persistindo em `localStorage` no modo desenvolvimento para simular um banco de dados local. Essa separação por stores mantém o código organizado e evita estados globais monolíticos.

Por fim, a camada de **API/back-end** é implementada usando as rotas do Next.js App Router (pasta `app/api`). O sistema possui rotas RESTful internas para recursos principais como eventos, briefings, equipe, vídeos e autenticacão. Cada rota é definida em um arquivo TypeScript que exporta handlers `GET`, `POST`, etc., usando a interface *Request/Response* do Next. Por exemplo, há rotas como `app/api/events/route.ts` para criar e listar eventos, `app/api/events/[eventId]/team/route.ts` para gerenciar equipe de um evento, `app/api/briefings/[eventId]/route.ts` para operações de briefing de um evento específico, e `app/api/events/[eventId]/videos/route.ts` para upload/importação de vídeos de um evento. Essas rotas atualmente usam estruturas em memória para armazenar os dados (simulando um banco de dados) e retornam respostas JSON para serem consumidas pelos serviços na camada de frontend. No App Router, o Next repassa automaticamente os parâmetros dinâmicos (como `eventId`) para essas funções via contexto; no código, vemos as funções definidas como, por exemplo, `export async function POST(request, { params })`, garantindo acesso a `params.eventId` dentro da implementação. Essa abordagem elimina problemas de parâmetros indefinidos e simplifica a lógica, já que não é necessário usar getServerSideProps ou semelhante nas páginas – as chamadas são feitas diretamente às rotas API com `fetch` ou através dos serviços criados.

## 2. Fluxo Completo do Usuário

O sistema MelhorApp contempla todo o ciclo de vida de um projeto audiovisual para eventos, desde a criação da conta até a entrega final dos vídeos aprovados. A seguir detalhamos o fluxo passo a passo, destacando as interações do usuário e as funcionalidades envolvidas em cada etapa:

1. **Criação de Conta e Login:** O usuário (seja um editor de vídeo interno ou um cliente) realiza o registro na plataforma informando nome, e-mail e senha. O sistema implementa validação básica (por exemplo, exigindo senha mínima de 6 caracteres e confirmação de senha) utilizando React Hook Form + Zod. Ao registrar ou fazer login, é atribuído um **papel (role)** ao usuário – por convenção, e-mails contendo a palavra “editor” são classificados como perfil *editor*, e-mails genéricos como *cliente*, enquanto um e-mail especial (e.g. **[admin@gonetwork.ai](mailto:admin@gonetwork.ai)**) é reconhecido como perfil *admin*. Essa definição de role é retornada pelo serviço de autenticação simulado. Atualmente, o login/registro é não persistente (apenas simulação local), mas já preparado para integração futura com API real (há trechos comentados que mostram como seria a chamada a um endpoint `/auth/login` ou `/auth/register`). Após login, o estado global de autenticação (`useAuthStore`) guarda os dados do usuário logado (ID, nome, email, role, avatar etc.) e marca o usuário como autenticado.

2. **Criação de Eventos:** Autenticado na aplicação, um usuário do tipo **editor** (ou admin) pode criar um novo evento/projeto audiovisual. Na interface, ele acessa a página **“Criar Novo Projeto”** (`/events/new`), preenche informações básicas como **título do projeto**, descrição, data do evento (caso seja uma filmagem ao vivo), data de entrega final desejada e quantidade de vídeos previstos para esse projeto. O sistema valida esses campos (por exemplo, título com mínimo de 3 caracteres, pelo menos 1 vídeo) antes de permitir a submissão. Ao confirmar a criação, uma chamada é feita à API interna (`POST /api/events`) para registrar o novo evento. O handler desta rota gera um **ID único** para o evento e monta um objeto representando o projeto com todos os campos preenchidos e estruturas padrão. Isso inclui inicializar um array de **tarefas** padrão do projeto (planejamento, gravação, edição, revisão, aprovação – todas inicialmente com status “pending”) e uma entrega de vídeo inicial vazia (um objeto representando “Vídeo 1” ainda sem versões enviadas, com status “editing”). Esses dados são armazenados em memória (`mockEvents`) simulando um banco de dados, e retornados ao front-end. No front-end, o novo projeto também é inserido no estado global (via `useProjectsStore.addProject` ou `createProject`), tornando-o imediatamente visível no **Dashboard** de projetos. Um toast de sucesso confirma a criação e o usuário é redirecionado para a página de detalhes do evento.

3. **Adição de Equipe e Clientes:** Dentro da página de detalhes do evento recém-criado, usuários com permissão (tipicamente o admin ou o editor responsável) podem cadastrar membros da **equipe** do projeto e associar um **cliente** ao evento. A equipe pode incluir outros editores, cinegrafistas, designers, etc., enquanto o cliente representa o representante do contratante que terá acesso para aprovar os vídeos. A interface da aba **Equipe** permite adicionar pessoas informando nome, papel/função, etc. Ao adicionar, o aplicativo realiza uma chamada `POST /api/events/[eventId]/team` para salvar esse membro na equipe do evento. A rota insere o novo membro em um array `team` mantido em memória (`mockTeamMembers`) vinculado àquele evento. De forma semelhante, pode-se designar o **cliente** do evento – normalmente o usuário que criou já é associado como cliente ou editor automaticamente. No estado atual, a associação de `clientId` e `editorId` ao projeto é feita no momento da criação do evento (ambos definidos como o usuário criador, temporariamente), mas a interface de equipe pode futuramente permitir transferência de responsabilidade. Após adicionar a equipe, todos os membros listados terão acesso aos detalhes do evento conforme seu papel (ver Permissões abaixo).

4. **Preenchimento do Briefing:** Uma funcionalidade crucial é o **Briefing do evento**, que coleta todas as informações detalhadas do projeto. O usuário (editor/admin) acessa a aba **Briefing** no detalhe do evento (`/events/[eventId]/briefing`) para preencher dados como data e horário do evento, local, requisitos técnicos, informações de credenciamento, detalhes de mídias necessárias, acesso à internet, etc. – tudo que for relevante para a produção audiovisual. O formulário de briefing utiliza validação robusta (React Hook Form com esquemas Zod) incluindo campos condicionais e obrigatoriedade de acordo com contexto (por exemplo, se o evento terá transmissão ao vivo, então exigir parâmetros de internet). Ao clicar em **Salvar Briefing**, os dados são enviados via `POST /api/briefings/[eventId]` para serem armazenados. No back-end simulado, esses dados são salvos em `mockBriefings` e também sincronizados no objeto do evento principal (`mockEvents`), atualizando campos-chave como data, local, etc., com as informações fornecidas no briefing. Assim, o briefing fica associado ao evento e disponível tanto para consulta quanto para edição posterior. Vale notar que há controle de acesso: apenas usuários autorizados (admin ou editor designado) podem editar o briefing, enquanto outros (como clientes) terão acesso somente leitura a essas informações.

5. **Geração da Timeline com base no Briefing:** Uma vez que o briefing é preenchido e salvo, o sistema **gera automaticamente um cronograma (timeline) de fases** do projeto utilizando os dados fornecidos. No handler do briefing (`POST /api/briefings/[eventId]`), após salvar os dados, invoca-se a função utilitária `generateScheduleFromBriefing()` para criar as fases planejadas. Essa função, definida em `lib/scheduleGenerator.ts`, calcula marcos do projeto como: fase de **Planejamento** inicial (do dia atual até a véspera do evento, ou alguns dias à frente se não há data de evento), fase de **Gravação** (se houver evento ao vivo, correspondendo à data do evento), fase de **Edição** (começando logo após o evento ou após planejamento, com duração proporcional ao número de vídeos, por exemplo **3 dias por vídeo** como valor padrão), fase de **Revisão** pelo cliente (cerca de **3 dias** adicionais após a edição), e fase de **Aprovação Final** (aproximadamente **1 dia** após a revisão). Caso o usuário tenha definido um prazo final (*finalDueDate*), o algoritmo ajusta as durações para não exceder essa data – encurtando a revisão ou edição se necessário, respeitando limites mínimos – de modo que a **entrega final** caiba no prazo estipulado. Todas essas fases são então salvas no campo `timeline` do objeto do evento. Na interface, o usuário pode visualizar o cronograma gerado acessando a aba **Timeline** do evento, que exibirá uma linha do tempo com cada fase marcada em ordem cronológica, com barras proporcionais à duração de cada fase e datas de início/fim planejadas. A representação visual destaca o status de cada fase: fases concluídas aparecem em verde, fases atrasadas (prazo planejado já passado sem conclusão) aparecem em vermelho, fases em andamento (data atual dentro do intervalo) em amarelo, e futuras pendentes em azul. Isso permite a todos os participantes acompanharem de forma clara o progresso do projeto e eventuais atrasos.

6. **Edição e Aprovação de Vídeos:** Após o evento e durante a fase de pós-produção, o foco está na **entrega dos vídeos** do projeto. Cada evento possui uma aba **Edição/Aprovação** onde ocorre o upload dos vídeos, iteração em versões, comentários do cliente e aprovações. Inicialmente, o projeto é criado com um deliverable (entregável) “Vídeo 1” vazio. O **editor** responsável poderá **fazer upload manual** de um arquivo de vídeo para essa entrega através da interface (um campo de upload). Internamente, ao selecionar um arquivo, a aplicação chama a função `addVideoVersion` do store, que cria uma nova **versão v1** para aquele vídeo, gera uma URL local (via `URL.createObjectURL`) e adiciona ao array de versões do deliverable. Imediatamente a interface reflete essa versão na lista, mostrando por exemplo “Vídeo 1 - v1” com opções de tocar o vídeo, adicionar comentários e marcar status. A plataforma suporta **múltiplas versões por vídeo** – cada novo upload gera v2, v3 e assim por diante, listadas em ordem. Assim, o editor pode ir substituindo ou acrescentando versões conforme edições são feitas.

   Além do upload manual, o sistema conta com um **Watcher de vídeos exportados** para agilizar o fluxo: trata-se de um script Node.js que fica monitorando uma pasta específica do servidor (por padrão `public/exports/`) e detecta quando um novo arquivo de vídeo é gerado por programas de edição externos. Ao identificar um novo arquivo, o watcher extrai o ID do evento do caminho da pasta (assumindo uma organização onde os vídeos exportados de cada projeto são salvos em subpastas nomeadas com o ID do evento) e automaticamente faz uma requisição `POST` para `api/events/[eventId]/videos`, passando o nome do arquivo detectado. A rota `/videos` então registra essa versão de vídeo no projeto: se não existir um deliverable, cria um novo, senão utiliza o existente, atribui **status “editing”** a ele e acrescenta a nova versão ao seu array, com URL apontando para o arquivo recém-chegado na pasta pública. Como resultado, sem que o editor precise fazer nada na interface, o vídeo exportado aparece automaticamente na plataforma (na aba Edição/Aprovação do evento) pronto para visualização. Essa integração economiza tempo e mantém o fluxo contínuo: o editor exporta do software de edição para a pasta configurada e o MelhorApp já captura e disponibiliza a versão ao cliente.

   Com o vídeo (ou versões múltiplas) disponível na plataforma, o **cliente** entra em ação para revisão. O MelhorApp oferece um player de vídeo interativo com capacidades de **anotação visual e comentários com timestamp**, possibilitando uma colaboração rica entre cliente e editor. O cliente pode reproduzir o vídeo e pausar em pontos específicos para deixar comentários contextualizados no tempo do vídeo, bem como desenhar marcações na tela (e.g. destacar um elemento no quadro que precisa de mudança). Cada comentário é registrado com o segundo exato do vídeo e fica associado ao deliverable. A comunicação é **em tempo real**: a aplicação utiliza *Socket.io* para que se o cliente adicionar um comentário ou anotação, o editor veja quase instantaneamente, e vice-versa. Esse recurso de colaboração em tempo real foi configurado com um proxy de Socket.io no Next.js para contornar CORS em desenvolvimento, e há um servidor Socket.io de teste incluso (ver seção técnica). A aba Edição/Aprovação contém também ferramentas para comparar versões lado a lado (o usuário pode selecionar duas versões e reproduzi-las sincronizadamente para ver diferenças), o que é útil quando o cliente quer conferir se a edição atendeu às solicitações anteriores.

   Durante o fluxo de revisão, o **editor** tem a opção de marcar manualmente quando uma versão está pronta para avaliação do cliente. Ao clicar no botão **“Marcar como pronto para revisão”**, o sistema muda o status daquele vídeo para **“ready\_for\_review”** e registra uma tarefa de revisão pendente (caso ainda não exista) no checklist do projeto, indicando que o cliente precisa revisar aquele material. O cliente, por sua vez, ao assistir a versão marcada como pronta, pode tomar uma de duas ações: **Aprovar** a entrega se estiver satisfeito, ou **Solicitar Alterações** caso contrário.

7. **Controle de Entregas e Status:** O sistema mantém controle rigoroso do estado de cada entregável (vídeo) e do projeto como um todo. Cada **vídeo deliverable** possui um atributo de **status** que evolui conforme o fluxo de trabalho: inicia normalmente como `"editing"` (em edição), pode passar para `"ready_for_review"` (quando o editor sinaliza que está pronto para o cliente revisar), pode ir para `"changes_requested"` (caso o cliente rejeite aquela versão e peça alterações), e finalmente `"approved"` (quando o cliente aprova a versão final). Esses status definem o que é exibido para cada usuário – por exemplo, um vídeo com status *ready\_for\_review* aparece destacado para o cliente como aguardando aprovação, enquanto *changes\_requested* indica ao editor que há modificações pendentes a fazer. Além do status do deliverable, existe também o conceito de **tarefas** (*tasks*) no nível do projeto que espelha as etapas do fluxo: por exemplo, “Revisão do vídeo pelo cliente” é uma tarefa criada quando um vídeo é enviado para revisão, e ao o cliente aprovar, essa tarefa é automaticamente marcada como *concluída*. Outras tarefas padrões (como “Planejamento do projeto”, “Gravação do vídeo”, “Edição do vídeo” etc.) podem ser marcadas manualmente ou automaticamente conforme as fases avançam. Dessa forma, o gestor do projeto tem tanto a visão macro do timeline/fases quanto a micro de tarefas concluídas ou pendentes.

   O sistema também gerencia **comentários** vinculados às entregas: cada comentário feito pelo cliente ao solicitar alterações fica registrado e pode ter seu status marcado como resolvido pelo editor quando a alteração correspondente for feita. Os comentários não são perdidos entre versões – permanecem associados ao deliverable mesmo após novas versões serem adicionadas, para histórico e rastreabilidade. Já as **versões** de vídeo permanecem listadas mesmo depois de substituídas: o editor pode apagar alguma versão da lista se desejar (por exemplo, um upload errado), mas caso contrário todas ficam acessíveis para comparação e histórico. Isso permite, por exemplo, que o cliente revise porque algo foi alterado de v1 para v2, etc.

   A interface ajuda a sinalizar o estado das entregas e fases: conforme mencionado, o componente de **Timeline** usa cores para indicar se uma fase está pendente, em andamento ou atrasada em relação às datas planejadas. Um projeto que ultrapassa a data final planejada sem aprovação terá a fase final em vermelho (indicando *atrasado*). Além disso, notificações visuais (toasts) e badges na UI indicam status – por exemplo, um vídeo com alterações solicitadas pode mostrar um rótulo de “Em edição” para o editor. Todo esse controle de status é gerenciado centralmente no store do projeto e refletido em tempo real nos componentes necessários, garantindo que todos os usuários vejam informações atualizadas.

8. **Upload e Gerenciamento de Assets:** Para cada projeto, o MelhorApp oferece uma aba **Assets** destinada a armazenar e organizar arquivos de mídia complementares – por exemplo, logos de patrocinadores, imagens de referência, documentos de roteiro, áudios ou outros recursos necessários à edição. A estrutura de assets funciona como uma biblioteca de arquivos do evento. Na implementação atual, a interface exibe uma lista de “pastas” e “arquivos” ilustrativa (p. ex. “Festival de Música” contendo 24 itens, “Teaser\_Festival\_v1.mp4” 120MB, etc.), mas o sistema por trás suporta efetivamente o upload de arquivos e gestão desses assets. No store global há um array de **assets** e funções para adicionar, atualizar ou remover assets. Quando um arquivo é **enviado (upload)** via interface, uma entrada `Asset` é criada contendo um ID, nome, tipo (imagem, vídeo, áudio ou documento) e a URL/localização do arquivo armazenado. Esses assets ficam vinculados ao projeto (há um campo `projectId` em cada asset para referência). Assim, tanto editores quanto clientes podem acessar a aba Assets para baixar materiais de apoio ou conferir todos os arquivos relacionados ao evento. Em termos de sincronização, a arquitetura global com Zustand assegura que, se um novo asset for adicionado por um usuário, os demais usuários com acesso ao projeto o vejam aparecer instantaneamente em tela. Isso é importante, por exemplo, quando um designer adiciona um novo logo na biblioteca de assets – o editor de vídeo saberá imediatamente que há um asset novo para usar.

9. **Permissões por Perfil (Admin, Editor, Cliente):** O controle de acesso e permissões é fundamental no MelhorApp para assegurar que cada usuário só veja e faça o que lhe compete. Existem três papéis principais definidos na estrutura de usuário: **admin**, **editor** e **cliente**. O **administrador** possui acesso irrestrito – consegue visualizar todos os projetos/eventos na plataforma, incluir/remover membros de qualquer equipe, ver todos os assets e modificar qualquer informação de briefing ou vídeos. Já um **editor** comum tem acesso apenas aos eventos em que está designado como membro da equipe (especialmente se for o editor responsável) e a eventos que ele próprio criou. Isso é implementado filtrando os projetos carregados conforme o usuário logado: por exemplo, na listagem de eventos o código cliente filtra `projects.filter(p => p.editorId === user.id || p.clientId === user.id)` para exibir somente aqueles onde o usuário aparece como editor ou como cliente do projeto. Da mesma forma, um **cliente** só enxerga os eventos onde foi cadastrado como cliente. Se um usuário tentar acessar via URL um evento que não faz parte, o back-end retornaria erro ou simplesmente não haveria dados para carregar.

   Além do acesso aos eventos, há restrições dentro de cada evento conforme o papel. Na aba de **Edição/Aprovação de Vídeos**, por exemplo, apenas editores veem o botão de **upload** de novas versões e podem marcar um vídeo como pronto ou excluir uma versão; já o cliente não vê essas opções de edição, mas em contrapartida é o único que vê os botões de **“Aprovar”** entrega ou **“Solicitar Alterações”** na interface. Essas condições estão implementadas nos componentes – por exemplo, o componente de ações do vídeo (`DeliverableActions`) checa `user.role` antes de renderizar certos botões (somente renderiza o botão de aprovar para role cliente, etc.). Outra restrição: somente editores podem marcar comentários como resolvidos (já que cabe a eles decidir quando uma observação do cliente foi atendida). De forma semelhante, a edição do briefing só é habilitada para admin/editores, enquanto clientes podem apenas visualizar. Em resumo, a UI e as rotas de API atuam em conjunto para aplicar as regras de permissão – as rotas checam se o usuário tem autorização (quando isso for relevante no futuro, e.g. via token JWT com role) e a UI já omite botões/ações não permitidas a determinado perfil, oferecendo assim uma **experiência customizada** para admin, editores e clientes.

## 3. Integração entre Funcionalidades

As funcionalidades do sistema estão integradas de forma coesa, de modo que ações em um módulo refletem em outros, garantindo um fluxo consistente. A seguir, destacamos como as principais partes “conversam” entre si:

* **Briefing ⟶ Timeline Automática:** O preenchimento do briefing alimenta automaticamente o cronograma do projeto. Conforme descrito, ao salvar os dados do briefing do evento, o back-end gera as fases da timeline com a função `generateScheduleFromBriefing` e atualiza o objeto do evento com essas fases. Isso significa que a **aba Timeline** fica praticamente pronta assim que o briefing é submetido – sem necessidade de o usuário inserir manualmente cada fase. Informações como **data do evento** influenciam diretamente o cronograma (inserindo uma fase de Gravação se houver data) e o **número de vídeos** informado dimensiona a duração da fase de edição (mais vídeos, mais dias). Toda essa lógica garante que o planejamento inicial e requisitos capturados no briefing sejam traduzidos em um plano de trabalho visual. Assim, se no briefing o usuário atrasar a data final do projeto, por exemplo, ele verá o reflexo disso no timeline (com fases mais espaçadas ou ajustadas). Essa integração reduz retrabalho e mantém briefing e cronograma sincronizados.

* **Watcher de Vídeos ⟶ Atualização da Aba de Edição:** O módulo de **watcher** atua como ponte entre ferramentas externas de edição de vídeo e o MelhorApp. Quando o editor de vídeo rendeza um arquivo final e salva na pasta monitorada (`public/exports/<eventId>/...`), o watcher detecta imediatamente o novo arquivo e **aciona a API interna de vídeos**. O request POST inclui o identificador do evento e nome do arquivo, permitindo que a aplicação crie uma nova versão daquele entregável automaticamente. A integração é feita via HTTP mesmo (usando `node-fetch` no script Node), aproveitando a rota interna que já existe. Uma vez que a versão é adicionada no back-end, o estado global do projeto é alterado (novo item em `event.videos[x].versions`) e, graças ao Zustand, todas as telas relevantes refletem essa mudança instantaneamente. O cliente, se estiver com a página aberta, verá surgir a versão nova na lista sem precisar dar refresh, e será notificado que há um vídeo novo para revisar. Essa arquitetura desacoplada (watcher externo chamando API) facilita escalar ou mover a lógica de ingestão de vídeos para outro serviço no futuro, se necessário. Importante ressaltar que o watcher define o status da entrega como *em edição* no momento do upload, ou seja, não presume que já esteja pronta para o cliente – isso fica sob controle do editor marcar quando apropriado. Mas poderia-se configurar para já marcar como *ready\_for\_review* automaticamente caso o processo de exportação já signifique versão final. Em resumo, a integração watcher + API de vídeos assegura que **nenhuma versão seja perdida** e elimina a etapa manual de upload pelo editor, acelerando o workflow.

* **Coordenando Comentários, Versões e Status:** O sistema foi projetado para que **comentários e versões de vídeo estejam alinhados** ao fluxo de revisão. Todos os comentários feitos durante a revisão pertencem a um determinado entregável (vídeo) e independem da versão específica – isto é, se o cliente comentar “Ajustar cor aqui” na v1 e o editor enviar uma v2, o comentário ainda fica registrado (não é apagado junto com a versão antiga). Desta forma, mantém-se um *histórico completo de feedback* centralizado no entregável, e o editor pode consultar os comentários anteriores ao preparar a nova versão. Se necessário, o sistema pode ser estendido para etiquetar comentários com o número da versão em que foram feitos, mas não foi obrigatório até então. A cada nova versão adicionada, não há perda de informação: versões anteriores continuam listadas e disponíveis para comparação ou restauro, e os comentários existentes continuam visíveis. Os **status** caminham em conjunto: quando o cliente solicita alterações em uma versão (ação “Solicitar Alterações”), o sistema marca o deliverable com status `"changes_requested"`, anexa o comentário do pedido de alteração (com timestamp 0 indicando talvez observação geral) e adiciona uma nova tarefa “Implementar alterações solicitadas” para o editor. O editor então trabalha na próxima versão, e ao fazer o upload ou ao concluir as mudanças, pode remover/completar essa tarefa conforme apropriado. Quando finalmente o cliente **aprova** uma versão, o status daquele vídeo passa a `"approved"` e o sistema automaticamente marca quaisquer tarefas pendentes de revisão como concluídas, além de notificar os usuários envolvidos. Todo esse encadeamento garante que **versões, comentários e status** estejam sempre consistentes: o histórico de versões oferece contexto, os comentários documentam o feedback em cada ciclo e os status/tarefas indicam exatamente em que pé está cada entrega (aguardando revisão, em edição, finalizado etc.).

* **Sincronização de Estado com Zustand:** A utilização do Zustand para estado global é fundamental para integrar todas as partes em tempo real. Em vez de cada componente buscar dados isoladamente no servidor, o aplicativo centraliza o estado do projeto em um único lugar (store) e diferentes componentes “escutam” as mudanças. Por exemplo, se o briefing for salvo e gerar novas fases de timeline, o store de projetos atualiza o array `timeline` do evento; imediatamente o componente da aba **Timeline** reflete essas novas fases sem recarregar a página. Da mesma forma, se o watcher adicionar uma versão de vídeo, ela é inserida no store e a aba **Edição/Aprovação** do respectivo evento passa a exibí-la instantaneamente. O mesmo acontece ao adicionar um membro na equipe ou um asset – quem estiver visualizando essas telas verá a atualização quase em simultâneo. Essa abordagem reativa evita inconsistências, pois todas as abas/leitores usam a **mesma fonte de verdade** (os dados do store ou via React Query cache, em casos de chamadas assíncronas). Além disso, a integração com Socket.io complementa essa sincronização ao notificar múltiplos clientes conectados sobre mudanças. Por exemplo, embora o sistema já atualize localmente o estado, poderia enviar via Web Socket um evento “newComment” para outros usuários do mesmo projeto, garantindo que se dois usuários (editor e cliente) estiverem com a página aberta simultaneamente, ações de um apareçam para o outro imediatamente. Em suma, o Zustand atua como **cola entre funcionalidades**, propagando os efeitos de cada ação do usuário ou do sistema para todos os cantos da aplicação, mantendo as informações unificadas e atualizadas em tempo real.

## 4. APIs e Rotas Importantes

O MelhorApp utiliza rotas REST internas (fornecidas pelo Next.js App Router) para realizar todas as operações de CRUD e ações do fluxo. Abaixo resumimos as principais rotas de API e seus comportamentos, bem como ajustes técnicos nelas:

* **Cadastro e Autenticação (API /auth)**: *(Simulado)* – Embora não haja rotas `app/api/auth` explícitas definidas (o login/registro está simulado no front-end pelo `auth-service.ts`), em um cenário real existiriam endpoints como `/api/auth/register` e `/api/auth/login`. O código já está preparado para utilizá-los: por exemplo, há comentários mostrando um fetch POST para `/auth/login` que retornaria dados do usuário. Na versão atual, as funções `loginUser` e `registerUser` simplesmente usam `simulateLogin`/`simulateRegister` para retornar um objeto usuário com ID gerado e role definido a partir do email. Ou seja, hoje a autenticação acontece no cliente (sem token JWT), mas a estrutura existe para futuras rotas reais.

* **Eventos (API `/api/events`):** É a rota responsável por **criar novos eventos** e **listar eventos existentes**. O método **GET** em `/api/events` retorna a lista de eventos. Atualmente, ele está implementado de forma simplificada sem filtro de usuário (retornando todos os eventos cadastrados no mock), mas a intenção de negócio é que: se o usuário for admin, veja todos os eventos; caso contrário, receba apenas eventos em que participa. Isso pode ser implementado futuramente checando o role e o userId (por ora, em ambiente simulado, esse filtro também é aplicado no front-end como citado). O método **POST** em `/api/events` permite criar um novo evento, lendo do corpo JSON os dados necessários (nome, cliente, editor responsável, data etc.). Ele gera um novo ID incremental para o evento e monta o objeto com campos default – status inicial, arrays vazios, uma entrega padrão e tarefas padrão. Em seguida, armazena em `mockEvents` e retorna o objeto criado com status 201. Essa rota simula o comportamento que no futuro seria persistir num banco de dados e retornar o registro criado. Também é importante notar que no Next.js 13, essa rota é definida em um arquivo único (não subdividido por verbo), e a função apropriada (GET ou POST) é escolhida conforme a requisição.

* **Detalhe de Evento (API `/api/events/[eventId]`):** Embora não explicitado no código fornecido, normalmente haveria um handler GET para retornar os detalhes de um evento específico (incluindo todos os dados aninhados: briefing, timeline, vídeos, equipe, etc.). Pelo padrão do App Router, isso poderia ser implementado em `app/api/events/[eventId]/route.ts` com um GET que busca `mockEvents[eventId]` e retorna. Caso o evento não exista, retorna 404. Como o front-end mantém muito desses dados no estado local após a criação, essa rota não foi detalhada no nosso código, mas seria trivial de acrescentar. De todo modo, o conteúdo do objeto evento já inclui praticamente tudo (com IDs referenciando a equipe e assets que poderiam ser obtidos em outras rotas).

* **Equipe (API `/api/events/[eventId]/team`):** Essa rota lida com membros da equipe de um evento. O método **GET** retorna a lista de membros da equipe para o `eventId` fornecido – essencial para popular a aba Equipe em modo visualização. O método **POST** adiciona um novo membro à equipe do evento. No código, temos um objeto `mockTeamMembers` separado que guarda arrays de membros por evento. Ao receber um POST com um corpo contendo um membro (espera-se algo como `{ id, name, role }` no JSON), o handler insere esse objeto no array correspondente ao eventId e retorna sucesso 201. Essa implementação é simples, sem regras de negócio complexas (não impede duplicados, por exemplo), já que é apenas para simulação. Em ambiente real, poderia validar se o usuário existe no sistema, atribuir um ID real de usuário, enviar notificação de convite, etc. Hoje cumpre o papel de permitir montar a lista de equipe.

* **Briefing (API `/api/briefings/[eventId]`):** Essa rota cuida do **conteúdo de briefing** de um evento. O método **GET** retorna o briefing salvo para aquele evento (ou erro 404 se não houver). O método **POST** recebe os dados do briefing (JSON) e os salva em `mockBriefings[eventId]`. Além disso, para conveniência, atualiza alguns campos principais no objeto do evento em `mockEvents` – por exemplo, se o briefing inclui `eventDate` ou `eventLocation`, ele copia esses valores para `mockEvents[eventId].date` e `.location` para manter consistência. A parte mais notável desta rota é que, após salvar, ela **(re)gera a timeline do projeto automaticamente** com base nos dados atualizados, chamando `generateScheduleFromBriefing`. As fases retornadas substituem o campo `timeline` do evento, efetivamente sincronizando o cronograma ao novo briefing. Por fim, retorna um `{ success: true }` indicando que o briefing foi salvo com sucesso. Esse design centralizado faz com que a lógica de geração da timeline fique no servidor, garantindo que qualquer cliente (web, mobile, etc.) que editar o briefing dispare o mesmo comportamento e regras de negócio.

* **Uploads de Vídeo (API `/api/events/[eventId]/videos`):** Esta rota foi adicionada para integrar com o watcher de vídeos e também permitir uploads via API. Ela processa **novas versões de vídeo** para um determinado evento. O método **POST** espera receber no corpo pelo menos um identificador do arquivo de vídeo (no nosso caso, passamos `{ fileName }` quando o watcher detecta um arquivo). Ao ser chamada, verifica se o evento existe no `mockEvents`; em caso negativo, responde 404. Se existe, determina a URL pública para acessar o arquivo recém-chegado (como `/exports/<eventId>/<fileName>` dentro da pasta pública do Next). Em seguida, atualiza ou cria o deliverable de vídeo: se o evento não tinha nenhum vídeo listado (o que não ocorre normalmente, pois criamos um por padrão), ele cria um novo; caso já tenha (p.ex. o “Vídeo 1”), utiliza esse. Define explicitamente o status do deliverable como `"editing"` (mantém em edição). Então cria um objeto de nova versão com um ID único (concatenando algo como `vid1-v2`), um nome (v2, v3, etc.), a URL do arquivo e um timestamp de upload. Esta versão é adicionada ao array `versions` do deliverable e o campo `updatedAt` do evento é atualizado (para fins de auditoria). Por fim, retorna sucesso. Em suma, essa rota insere no sistema o conhecimento de que um novo arquivo de vídeo foi enviado para aquele projeto. Vale mencionar que poderíamos estender essa mesma rota para receber uploads diretos do frontend (enviando binário do vídeo ou URL do armazenamento), mas no escopo atual, ela é utilizada em conjunto com o watcher Node que já coloca o arquivo na pasta pública.

* **Watcher de Vídeos (Script Node.js):** Embora não seja uma “rota” HTTP, é parte importante da arquitetura de integração. O script localizado em `scripts/video-watcher.js` deve ser executado em paralelo ao servidor Next. Ele utiliza a biblioteca **chokidar** para observar o diretório `public/exports` por novos arquivos. Ao detectar um arquivo criado (`'add'`), registra no console e extrai o ID do evento do caminho do arquivo (assumindo o formato mencionado). Então ele monta a URL da API interna (`http://localhost:3000/api/events/<eventId>/videos`) – por padrão o Next dev roda na porta 3000 – e faz um **fetch POST** enviando o nome do arquivo em JSON. Se a resposta for OK, loga sucesso no console; em caso de erro, loga o erro para diagnóstico. Para ativar o watcher, é necessário instalar suas dependências (`npm i chokidar node-fetch`) e rodá-lo. O projeto inclui um comando sugerido `"watch:videos": "node scripts/video-watcher.js"` e combina com o comando de dev utilizando a ferramenta *concurrently*, de forma que ao rodar `npm run dev:all` o Next.js, o servidor de socket de teste e o watcher iniciem juntos. Esse watcher foi concebido para ambientes de demonstração e desenvolvimento local, permitindo apresentar a funcionalidade de envio automático de vídeos sem precisar de um servidor de armazenamento especializado.

* **Rotas Dinâmicas e Contexto de Parâmetros:** Durante o desenvolvimento, houve cuidado especial em corrigir o uso de parâmetros dinâmicos nas rotas do Next.js App Router. No formato atual, as rotas definidas em arquivos dentro de `[eventId]` recebem o objeto `{ params }` do contexto – por exemplo, `export async function GET(request, { params })` – em vez de tentar acessar variáveis globais ou closures de nível acima. No conteúdo já apresentado, vemos isso nas rotas de equipe, briefing, vídeos, etc., usando `{ params: { eventId } }` na assinatura da função. Isso evita erros onde `params.eventId` aparece como indefinido. Do lado do cliente (componentes React), para páginas dinâmicas usamos o hook `useParams()` do Next Navigation para obter o `eventId` atual quando precisamos fazer fetch de dados ou chamadas de ação para aquele contexto específico. Essa é a forma correta no App Router de identificar qual recurso está sendo manipulado. Graças a essa padronização, endpoints como as rotas de API e páginas de evento/briefing funcionam sem problemas de identificação do recurso correto.

## 5. Observações Técnicas e Configurações

### Porta de Desenvolvimento e `next.config.mjs`

Durante a implementação, ajustou-se a configuração do Next.js para assegurar o uso correto das portas e do proxy interno. Inicialmente, havia uma tentativa de especificar a porta de desenvolvimento diretamente no `next.config.mjs` (usando uma chave não suportada `devServer`), o que foi removido para evitar warnings e efeitos inesperados. A forma adequada de definir a porta em ambiente dev é ao executar o comando, por exemplo `next dev -p 3001`. No arquivo de configuração, mantivemos apenas opções válidas como `eslint.ignoreDuringBuilds`, `typescript.ignoreBuildErrors` (para agilizar builds em ambiente de teste), `images.unoptimized` e a regra de `rewrites()` para o Socket.io. Este rewrite configura o front-end para redirecionar qualquer chamada a `/socket.io/*` para o servidor Socket.io rodando na porta 3001, permitindo que o código cliente (`io()` do Socket.io) se conecte corretamente ao backend em desenvolvimento. Com isso, o fluxo é: desenvolvendo localmente, podemos rodar o Next na porta 3000 e um servidor Socket.io de teste na 3001 – o proxy do Next intercepta as conexões do cliente e as envia para 3001.

Entretanto, para a demonstração do vídeo **rodando localmente**, optou-se por rodar o Next.js também na porta **3001** para evitar conflitos, já que o Socket.io de teste pode ser configurado para outra porta. Nos scripts de exemplo fornecidos, vemos o `"dev": "next dev -p 3001"` e o Socket.io sendo executado via `"socket-server": "node scripts/socket-server-teste.js"` (nesse caso o socket-server-teste foi ajustado para talvez usar 3002, por exemplo). Também adicionamos `"watch:videos"` e combinamos tudo em `"dev:all"` com *concurrently*. Vale destacar que em produção, a porta do Next é decidida pela plataforma de hosting e a comunicação com Socket.io deve usar a variável de ambiente `NEXT_PUBLIC_SOCKET_URL` conforme mencionado na documentação do README. Em suma, a configuração final do `next.config.mjs` ficou enxuta e correta, e a instrução para rodar localmente é usar `npm run dev -- -p 3001` ou ajustar o package.json, ao invés de tentativas de configuração interna da porta. Essa mudança eliminou erros e garantiu que tanto o front-end quanto o servidor de socket pudessem rodar simultaneamente sem conflito de porta.

### Execução Local com Vídeo Funcional (Sem Backend Externo)

Uma grande vantagem do MelhorApp, em sua versão atual, é que ele pode ser executado **integralmente em ambiente local** para propósitos de demo, **sem dependências de backend externas**. Todo o back-end necessário roda dentro do próprio Next.js (através das rotas API simuladas) e de pequenos scripts Node auxiliares. Em outras palavras, não é preciso configurar um banco de dados ou servidor separado – o armazenamento é todo em memória (reiniciado a cada execução) e, para fins de demonstração, isso é suficiente. Para rodar a aplicação completa localmente, seguimos os passos:

1. **Instalar Dependências:** `npm install` no repositório instala tanto as dependências do front (Next, React, Zustand etc.) quanto as do watcher e outras ferramentas (chokidar, node-fetch, concurrently, etc.).
2. **Iniciar o Servidor de Socket de Teste:** opcionalmente, rodar `npm run socket-server` para subir um pequeno servidor Socket.io local (definido em `scripts/socket-server-teste.js`) que emite eventos de demonstração.
3. **Iniciar o Watcher de Vídeo:** em outra janela, rodar `npm run watch:videos` para começar a monitorar a pasta de exports (se for demonstrar a funcionalidade de auto-upload de vídeos).
4. **Iniciar o Front-end:** `npm run dev` (ou, como configurado no pacote, `npm run dev:all` para fazer tudo de uma vez com *concurrently*). Isso iniciará o Next.js na porta configurada (3000 ou 3001) e disponibilizará o aplicativo em `http://localhost:3001` (conforme config).

Com isso, consegue-se testar **todas as funcionalidades**: criar usuários (lembrando que as credenciais de demo são [admin@gonetwork.ai](mailto:admin@gonetwork.ai) / admin, que será reconhecido como admin no sistema), criar eventos, fazer uploads de vídeos (o arquivo selecionado pode ser qualquer vídeo local para simular uma versão), adicionar comentários e ver a interação em tempo real se abrir duas janelas (uma como editor, outra como cliente, por exemplo). Como os dados são armazenados em memória (e no estado do navegador via Zustand persist, em alguns casos), não há necessidade de configurar banco – porém, isso também significa que ao dar refresh ou reiniciar o servidor, os dados voltam ao estado inicial pré-cadastrado (há alguns eventos de exemplo no mock, como ID 123 e 456 que podem ser carregados). Essa abordagem de **simulação local** foi deliberadamente adotada para fins de *MVP* e demonstração para investidores, reduzindo complexidade de infra no curto prazo. Os serviços de API foram abstraídos de forma que, quando for o momento de integrar um back-end real, basta trocar as implementações simuladas por chamadas HTTP reais (o que já está parcialmente codificado e apenas comentado). Em resumo, o ambiente local fornece uma experiência quase idêntica ao produto final pretendido, apenas sem persistência real – ideal para validar o conceito e a aceitação dos usuários antes de investir em infraestrutura server-side.

## 6. Direcionamento Técnico Final

Por fim, avaliamos o estado atual do MelhorApp em termos do que está plenamente funcional e pronto para apresentação, quais partes ainda são simplificadas/simuladas, e apontamos recomendações para evoluir o sistema visando um produto robusto e escalável:

### Funcionalidades Concluídas e Demonstração

A plataforma MelhorApp, em sua versão protótipo, já entrega **todas as funcionalidades-chave** de forma integrada, permitindo uma demonstração fiel do caso de uso. Isso inclui: o fluxo completo de cadastro/login de usuários (com papéis distintos), a criação e gerenciamento de projetos de eventos, a edição colaborativa de vídeos com upload de múltiplas versões, marcações visuais e comentários no player de vídeo, e o fluxo de aprovação com alterações solicitadas pelo cliente. A interface do usuário está implementada com componentes profissionais (design system) e é responsiva, adaptando-se de desktop a dispositivos móveis. O sistema de **timeline inteligente** mostra automaticamente o planejamento do projeto, e o **sistema de status** indica claramente o andamento de cada entrega (pendente, em revisão, aprovado, etc.). A colaboração em tempo real via Socket.io está configurada e pode ser demonstrada (por exemplo, dois usuários adicionando comentários simultaneamente). Além disso, recursos auxiliares como gerenciamento de equipe e assets estão presentes para ilustrar o ecossistema completo da aplicação de produção audiovisual. Em suma, o MVP está **pronto para apresentação**: um investidor ou stakeholder técnico pode criar um evento fictício, simular o upload de um vídeo, fazer um ciclo de feedback e aprovação e visualizar todas as partes do sistema funcionando em conjunto – demonstrando claramente o valor da ferramenta em otimizar a comunicação entre editores e clientes.

### Limitações e Implementações Simuladas

Apesar de funcional em termos de interface e fluxo, algumas partes do sistema ainda estão implementadas de forma simplificada ou simulada, apropriadas para demonstração mas que exigirão evolução para produção. O armazenamento de dados atualmente é **volátil em memória** – não há um banco de dados real por trás. Isso significa que dados de eventos, briefings, usuários, etc., não persistem de verdade (a não ser no local storage do browser via Zustand persist, o que é apenas uma cache local). Da mesma forma, a autenticação é fictícia: não há verificação de senha de fato nem gerenciamento de sessão/token; qualquer e-mail não previamente usado pode se “registrar” e será aceito. Esses atalhos são aceitáveis em desenvolvimento e demonstração, mas precisam ser substituídos por componentes reais (e seguros) mais adiante. Outra limitação é que as **APIs internas não aplicam validações robustas de autorização** – por exemplo, nada impede pelo back-end simulado que um usuário mal-intencionado tente acessar `/api/briefings/123` de um evento que não é seu. No contexto demo isso não é problemático, pois assumimos cooperação, mas em produção precisaríamos de middleware de autenticação/autorização usando tokens JWT ou cookies seguros, verificando o role e associação do usuário antes de retornar/alterar dados. Além disso, as funcionalidades de envio de e-mail, notificações externas, etc., não estão implementadas – toda notificação é apenas interna (toasts na tela). A integração com serviços terceiros (por exemplo, armazenamento de vídeos em CDN ou uso de encoding server) também não foi feita; no protótipo os vídeos são servidos diretamente do filesystem local, o que não escalaria para produção. Em resumo, **persistência e segurança** são os principais pontos simulados – eles não afetam a demonstração do conceito, mas precisariam de atenção antes de um lançamento real.

### Recomendações para Evolução Futura (Banco de Dados e Escalabilidade)

Para avançar o MelhorApp de um protótipo para um produto robusto, recomendamos focar em: **Implementar um banco de dados real e API persistente**, e **preparar a aplicação para escala**. Em primeiro lugar, substituir as estruturas `mockEvents`, `mockBriefings`, etc., por um banco de dados relacional ou NoSQL conforme adequado. Um *backend* poderia ser desenvolvido (em Node.js/Express, ou serverless functions no próprio Next.js API) com conexão a um DB (PostgreSQL, MongoDB, etc.), garantindo persistência das informações de usuários, eventos, vídeos, comentários, etc. O código atual já está bem modularizado para isso – os serviços do front (`auth-service`, `briefing-service`, etc.) podem passar a chamar endpoints reais simplesmente removendo as simulações e descomentando os fetchs preparados. Com um backend real, poderá ser implementado um sistema de autenticação robusto (com hash de senhas, JWT para sessões, e controle de autorização nas rotas).

Em termos de escalabilidade, é importante considerar o **armazenamento de vídeos**: em produção, os arquivos de vídeo podem ser grandes e seria mais eficiente armazená-los em um serviço de cloud storage (como AWS S3 ou Google Cloud Storage) e usar CDN para entregá-los aos clientes, em vez de servir diretamente do servidor Next. O módulo de watcher poderia ser adaptado para, ao invés de apenas mover arquivos locais, integrar com webhooks de um serviço de render (por exemplo, se a renderização ocorrer na nuvem, o serviço de encoding notificaria nossa API de um novo vídeo pronto). Também seria recomendado adicionar **transcoding** dos vídeos para diferentes qualidades, mas isso já foge do escopo imediato.

No front-end, a estrutura com Zustand e Socket.io já suporta múltiplos usuários simultâneos e atualizações em tempo real; para produção, deve-se configurar corretamente os namespaces/salas do Socket.io para cada projeto e assegurar autenticação nos canais (impedir que um usuário ouça eventos de projetos alheios). A documentação já traça planos para melhorias nesse sentido, como aprimorar notificações em tempo real quando briefings forem atualizados ou quando novas versões forem enviadas – implementar esses alertas garantiria engajamento e informação imediata a todos os envolvidos.

Por fim, convém investir na **observabilidade e qualidade**: adicionar logs estruturados no backend, monitoramento de desempenho (p. ex. quantos segundos leva upload e processamento de um vídeo), e testes automatizados para as funções críticas (geração de timeline, fluxo de aprovação). Como melhorias de produto, pode-se implementar sistema de **histórico de alterações** (log de quem fez o quê e quando, por exemplo no briefing), versãoamento de briefing e documentos, e integração com calendário (para lembrar datas de evento e prazos). Essas adições aumentariam o valor da plataforma para clientes empresariais.

Em resumo, o MelhorApp apresentou-se arquiteturalmente bem estruturado e **pronto para evoluir** – os próximos passos naturais são acoplar um banco de dados real para persistência, fortalecer a camada de autenticação/autorização, e mover do protótipo local para uma infraestrutura cloud, garantindo escalabilidade para atender múltiplos eventos e usuários simultâneos sem degradação de performance. Com essas evoluções, a ferramenta estará preparada para uso em produção e expansão comercial, mantendo a base sólida que foi demonstrada aos investidores.
